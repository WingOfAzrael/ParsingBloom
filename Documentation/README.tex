\documentclass{article}
\usepackage{geometry}
\geometry{legalpaper, portrait, margin=1.1in}
\setlength{\parskip}{1em}
\renewcommand{\baselinestretch}{1.4}


\title{ParsingBloom}

\date{Version 0.5.0}
\begin{document}
	
	\maketitle
	
	\section{Introduction}
	ParsingBloom is a proof-of-concept pipeline that turns raw transaction emails into analytics-ready records.  Its goal is to showcase open-source transformer-based LLMs in end-to-end ETL, producing high-quality, schema-validated JSON and CSV outputs.
	
	\section{Key Ideas}
	\begin{tabular}{@{}p{4cm}p{10cm}@{}}
		\toprule
		\textbf{Principle} & \textbf{What it means in code} \\ \midrule
		Deterministic output & Every run over the same inputs yields bit-identical JSON; both identity and structure tests enforce this. \\
		Connector abstraction & Gmail connector ships today; any IMAP, REST, or webhook source can be plugged in behind the same interface. \\
		Hybrid parsing & LLM\,first strict JSON extraction, with deterministic regex fallback if validation fails. \\
		Dynamic schema support (0.5) & Drop a YAML spec in \texttt{config/schemas/}; Pydantic validates and exports exactly those fields. \\
		\bottomrule
	\end{tabular}
	
	\section{Determinism Tests}
	\begin{itemize}
		\item \textbf{Identity tests} – byte-for-byte equality of two outputs.  
		\item \textbf{Structure tests} – identical field names and types, even if values differ.  
	\end{itemize}
	Passing both means the pipeline is \emph{self-consistent}.
	
	\section{Usage}
	\texttt{export HF\_API\_TOKEN=hf\_xxx}
	
	\subsection{Local}
	\begin{verbatim}
		chmod +x deploy/deploy_pb.sh
		bash deploy/deploy_pb.sh
	\end{verbatim}
	\textbf{Options} (override \texttt{config.yaml}):
	\begin{description}
		\item[\texttt{--gpus}] Enable CUDA if available.
		\item[\texttt{--force}] Reinstall dependencies, overwrite build artifacts.
		\item[\texttt{--runs N}] Number of replicates (default 1).
		\item[\texttt{--out-dir DIR}] Base output directory.
		\item[\texttt{--schedule MODE}] Daemon mode: \texttt{hourly}, \texttt{daily}, or cron.
	\end{description}
	
	\subsection{Docker}
	\begin{verbatim}
		deploy/deploy_docker.sh
	\end{verbatim}
	Same options as Local.
	
	\subsection{Determinism Testing Framework}
	\begin{verbatim}
		chmod +x deploy/deploy_determinism.sh
		bash deploy/deploy_determinism.sh --runs 30
		python pipeline/determinism_plot.py --dir data/determinism_tests
	\end{verbatim}
	
	\section{Full Explanation of System Behavior}
	\begin{enumerate}
		\item Authenticate to Gmail and fetch new messages.
		\item Send each email body to an LLM (OpenAI, llama-cpp, HuggingFace) with a strict JSON prompt.
		\item If validation fails, run a regex fallback to extract core fields.
		\item Support dynamic schema creation via YAML and Pydantic.
		\item Each run writes a per-run CSV and appends to a master CSV.
		\item Track run metadata (start/end times, counts) and flag ambiguous items.
		\item Offer a monitoring script to compute z-scores on run sizes for anomalies.
		\item (Planned) keep daemon alive until termination.  
	\end{enumerate}
	
	\section{Systems Key Features and Problems They Solve}
	\begin{itemize}
		\item Configuration-driven scheduling (APScheduler + cron).  
		\item Hybrid parsing (LLM first + regex fallback).  
		\item Per-run + master CSV exports for auditability.  
		\item Attachment handling via \texttt{pdfplumber}.  
		\item Lightweight drift monitoring decoupled from core logic.  
		\item Flagging mechanism for ambiguous or failed parses.  
		\item Self-diagnosis with meta-analytics on system metadata.  
	\end{itemize}
	
	\section{Technologies Used}
	\begin{itemize}
		\item \textbf{HuggingFace Transformers}: \texttt{meta-llama/Llama-3.2-3B-Instruct}.  
		\item OpenAI, llama-cpp, and HuggingFace APIs (unquantized & quantized).  
		\item Standard Python libraries for CSV, logging, metrics, etc.  
	\end{itemize}
	
	\section{Manual Deployment Instructions}
	\begin{enumerate}
		\item Clone and install:
		\begin{verbatim}
			git clone https://github.com/you/ParsingBloom.git
			cd ParsingBloom
			conda create -n pb python=3.10
			conda activate pb
			pip install -r requirements.txt
		\end{verbatim}
		\item Configure:
		\begin{itemize}
			\item Copy \texttt{config/config.yaml.example} $\to$ \texttt{config/config.yaml}.  
			\item Set Gmail OAuth2 secrets, KMS/Vault settings, scheduler, etc.  
		\end{itemize}
		\item Run scheduler or one-off:
		\begin{verbatim}
			python schedule_runner.py
			SCHEDULE_CRON="0 0 * * *" python schedule_runner.py
			python pipeline/run_pipeline.py --start-date 2023-01-01
		\end{verbatim}
	\end{enumerate}
	
	\section{Determinism Tiers}
	\begin{tabular}{@{}lllll@{}}
		\toprule
		\textbf{Tier} & \textbf{Scope \& Goal} & \textbf{Required Tests} & \textbf{When to Use} & \textbf{Effort}\\ \midrule
		1 Audit-Ready & Stable \& timely & 30× runs, 100\% field match, CV<5\% & Standard SLAs & Low \\
		2 Engineering-Grade & Catch nondeterminism & Prompt+\!output hashes, cross-env spot checks & Infra churn & Medium \\
		3 Regulated-Grade & Compliance \& SLAs & Grid tests, stochastic envelope, 3σ control charts & Finance, healthcare & High \\
		\bottomrule
	\end{tabular}
	
	\section{Configuration Loading Logic}
	The \texttt{load\_config()} function finds \texttt{config.yaml} via:
	\begin{enumerate}
		\item Explicit \texttt{path} argument  
		\item \texttt{PARSINGBLOOM\_CONFIG} or \texttt{PARSINGFORGE\_CONFIG} env var  
		\item \texttt{<project\_root>/config/config.yaml}  
	\end{enumerate}
	It infers a default connector if only one is defined, and respects \texttt{PARSINGBLOOM\_DEVICE} overrides.  Fields are loaded into \texttt{FullConfig} with Pydantic validation :contentReference[oaicite:0]{index=0}.
	
	\section{Run Tracking \& Metadata}
	\texttt{RunTracker} logs each execution:
	\begin{itemize}
		\item \texttt{start\_run()} generates a UUID and UTC timestamp.  
		\item \texttt{end\_run(fetched, processed, last\_time)} appends to \texttt{runs.csv} and overwrites \texttt{metadata.csv}.  
	\end{itemize}
	All stored under \texttt{data/} for audit trails :contentReference[oaicite:1]{index=1}:contentReference[oaicite:2]{index=2}.
	
	\section{Metrics \& Monitoring}
	Prometheus metrics are exposed on port 8000:
	\begin{itemize}
		\item \texttt{emails\_fetched\_total}, \texttt{parse\_success\_total}, \ldots  
		\item Histogram of \texttt{llm\_latency\_seconds}  
	\end{itemize}
	Endpoint spun up by \texttt{start\_metrics\_server()} :contentReference[oaicite:3]{index=3}:contentReference[oaicite:4]{index=4}.
	
	\section{Database Loaders}
	Dual-loader in \texttt{db\_loader.py}:
	\begin{itemize}
		\item \texttt{load\_postgres()} uses SQLAlchemy to append to Postgres if configured.  
		\item \texttt{load\_snowflake()} connects via Snowflake connector and uploads CSV.  
		\item Silent skips if environment not present :contentReference[oaicite:5]{index=5}:contentReference[oaicite:6]{index=6}.
	\end{itemize}
	
	\section{Exporters \& Schema Enforcement}
	\texttt{TransactionExporter}:
	\begin{itemize}
		\item Reads existing max \texttt{transaction\_id}, assigns new IDs.  
		\item Fast-path append when dates are monotonic; otherwise merge in O(N+M).  
		\item Per-run snapshots, flagged-message logging.  
	\end{itemize}
	Schema fields driven by Pydantic models :contentReference[oaicite:7]{index=7}:contentReference[oaicite:8]{index=8}.
	
	\section{Tier-2 Determinism Hook}
	A hook in \texttt{pipeline\_execute.py} writes out run metadata, the last LLM prompt text, and model name for cross-run reproducibility.
	
	\section{Security, Backups \& Deployment Best Practices}
	\begin{itemize}
		\item Use LUKS or cloud KMS (e.g. Vault) for config and token encryption.  
		\item Encrypted backups of \texttt{data/} directory; restore via secure key.  
		\item Retry policies for connector and database uploads.  
	\end{itemize}
	
	\section{Meta-Analysis \& Cybersecurity Research}
	Capture and analyze operational logs, performance metrics, and drift signals to feed anomaly detection, audit trails, and forensic analysis.
	
	\section{Extensible Modularity}
	Connectors, parsers, exporters, loaders, and analysis scripts live in separate modules, allowing new data sources or sinks to be added with minimal changes :contentReference[oaicite:9]{index=9}:contentReference[oaicite:10]{index=10}.
	
	\section{Roadmap Toward GAIA}
	\begin{description}
		\item[v0.6: Determinism \& Reliability] Output hashing, prompt logging, cross-env testing, basic alerting.  
		\item[v0.7: Statistical Quality Control] 3σ control charts, Clopper–Pearson intervals, multi-backend cross-validation.  
		\item[v0.8: Agentic Layer Integration] Add GAIA orchestrator, tool registry, execution engine wrapping ParsingBloom modules.  
		\item[v0.9: Memory \& Learning] Vector-store memory, critic loop, embedded physics for complex reasoning.  
		\item[v1.0: GAIA] Full Jarvis-style agentic assistant in interactive and batch modes, with regulated-grade auditability.  
	\end{description}
	
\end{document}
